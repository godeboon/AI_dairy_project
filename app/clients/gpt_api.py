from openai import OpenAI
from fastapi.responses import StreamingResponse
from app.config.settings import settings

# API í‚¤ ê²€ì¦ ë° ë””ë²„ê¹…
print(f"ğŸ” ë””ë²„ê¹…: settings.openai_api_key ê¸¸ì´ = {len(settings.openai_api_key) if settings.openai_api_key else 0}")
print(f"ğŸ” ë””ë²„ê¹…: settings.openai_api_key ì‹œì‘ = {settings.openai_api_key[:10] if settings.openai_api_key else 'None'}...")

if not settings.openai_api_key:
    print("âš ï¸ ê²½ê³ : OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
else:
    print(f"âœ… OpenAI API í‚¤ ì„¤ì •ë¨: {settings.openai_api_key[:20]}...")

# settingsì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
client = OpenAI(api_key=settings.openai_api_key)

# ì‘ë‹µì˜¤ëŠ” ë°©ì‹ í•œë²ˆì— ì™„ì„±ëœ ë¬¸ì¥ ë³´ë‚¼ìˆ˜ ìˆëŠ” api
def call_gpt(prompt: list) -> str:
    try:
        response = client.chat.completions.create(
            model="gpt-4-1106-preview",
            messages=prompt
        )
        return response.choices[0].message.content
    except Exception as e:
        error_msg = str(e)
        if "401" in error_msg:
            print("âŒ OpenAI API í‚¤ ì¸ì¦ ì‹¤íŒ¨. .env íŒŒì¼ì— ì˜¬ë°”ë¥¸ OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        elif "429" in error_msg:
            print("âŒ OpenAI API ìš”ì²­ í•œë„ ì´ˆê³¼. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
        else:
            print("âŒ GPT í˜¸ì¶œ ì‹¤íŒ¨:", error_msg)
        raise

# ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ gpt ì˜ api í˜¸ì¶œ
async def stream_gpt_response(messages: list):
    try:
        response = client.chat.completions.create(
            model="gpt-4-1106-preview",
            messages=messages,
            stream=True
        )
        for chunk in response:
            if chunk.choices[0].delta.content:
                yield chunk.choices[0].delta.content
    except Exception as e:
        error_msg = str(e)
        if "401" in error_msg:
            yield "âŒ API í‚¤ ì¸ì¦ ì‹¤íŒ¨. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."
        elif "429" in error_msg:
            yield "âŒ ì„œë¹„ìŠ¤ ì¼ì‹œì  ê³¼ë¶€í•˜. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”."
        else:
            yield "âŒ GPT ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ ë°œìƒ"
        print("âŒ GPT ìŠ¤íŠ¸ë¦¬ë° ì‹¤íŒ¨:", error_msg)





# í´ë˜ìŠ¤ ë²„ì „ (ì¼ê¸° ìƒì„±ìš©)
class GPTClient:
    def __init__(self):
        self.client = OpenAI(api_key=settings.openai_api_key)

    # ì‘ë‹µì˜¤ëŠ” ë°©ì‹ í•œë²ˆì— ì™„ì„±ëœ ë¬¸ì¥ ë³´ë‚¼ìˆ˜ ìˆëŠ” api
    async def call_gpt(self, prompt: str) -> str:
        try:
            response = self.client.chat.completions.create(
                model="gpt-4-1106-preview",
                messages=[{"role": "user", "content": prompt}]
            )
            return response.choices[0].message.content
        except Exception as e:
            error_msg = str(e)
            if "401" in error_msg:
                print("âŒ OpenAI API í‚¤ ì¸ì¦ ì‹¤íŒ¨. .env íŒŒì¼ì— ì˜¬ë°”ë¥¸ OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
            elif "429" in error_msg:
                print("âŒ OpenAI API ìš”ì²­ í•œë„ ì´ˆê³¼. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
            else:
                print("âŒ GPT í˜¸ì¶œ ì‹¤íŒ¨:", error_msg)
            raise

    # ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ gpt ì˜ api í˜¸ì¶œ
    async def stream_gpt_response(self, prompt: str):
        try:
            response = self.client.chat.completions.create(
                model="gpt-4-1106-preview",
                messages=[{"role": "user", "content": prompt}],
                stream=True
            )
            for chunk in response:
                if chunk.choices[0].delta.content:
                    yield chunk.choices[0].delta.content
        except Exception as e:
            error_msg = str(e)
            if "401" in error_msg:
                yield "âŒ API í‚¤ ì¸ì¦ ì‹¤íŒ¨. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."
            elif "429" in error_msg:
                yield "âŒ ì„œë¹„ìŠ¤ ì¼ì‹œì  ê³¼ë¶€í•˜. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”."
            else:
                yield "âŒ GPT ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ ë°œìƒ"
            print("âŒ GPT ìŠ¤íŠ¸ë¦¬ë° ì‹¤íŒ¨:", error_msg) 